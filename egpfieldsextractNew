import zipfile
import re
import csv
from collections import defaultdict

def extract_data_sources_and_fields_to_csv(egp_file, output_csv):
    # Extract the EGP file (essentially a ZIP file)
    with zipfile.ZipFile(egp_file, 'r') as z:
        # Look for .sas files and metadata within the project
        sas_files = [f for f in z.namelist() if f.endswith('.sas') or f.endswith('.xml')]

        # Data structures
        data_fields = defaultdict(set)  # Map of database.table -> variables

        # Regex patterns
        table_regex = re.compile(
            r'\b([a-zA-Z0-9_]{9,}\.[a-zA-Z0-9_]+)\b',  # Matches `database.table`
            re.IGNORECASE
        )
        table_alias_regex = re.compile(
            r'\b([a-zA-Z0-9_]{9,}\.[a-zA-Z0-9_]+)\s+(?:as\s+)?([a-zA-Z0-9_]+)', 
            re.IGNORECASE
        )  # Matches `database.table alias` or `database.table AS alias`
        field_regex = re.compile(
            r'\b([a-zA-Z0-9_]+)\.(\w+)\b',  # Matches `alias.variable` or `database.table.variable`
            re.IGNORECASE
        )

        alias_map = {}  # Map of alias -> database.table

        for file in sas_files:
            with z.open(file) as f:
                try:
                    content = f.read().decode('utf-8', errors='ignore')  # Read file content

                    # Extract all tables and aliases
                    for table, alias in table_alias_regex.findall(content):
                        alias_map[alias] = table  # Map alias to table
                        data_fields[table]  # Ensure table exists in the map

                    # Capture all standalone database.table references
                    for table in table_regex.findall(content):
                        data_fields[table]  # Ensure table exists in the map

                    # Extract variables and map them to tables
                    for alias, field in field_regex.findall(content):
                        if alias in alias_map:  # If alias maps to a table
                            table = alias_map[alias]
                            data_fields[table].add(field)
                        elif alias in data_fields:  # If alias is directly a table
                            data_fields[alias].add(field)
                except Exception as e:
                    print(f"Error reading {file}: {e}")

    # Write Data Source Fields to CSV
    with open(output_csv, 'w', newline='') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(["Database.Table", "Variable"])  # Header
        for table, fields in data_fields.items():
            if fields:  # If variables exist for the table
                for field in sorted(fields):
                    writer.writerow([table, field])
            else:  # Write the table even if no variables were found
                writer.writerow([table, ""])

    print(f"Data source fields saved to {output_csv}")

# Usage example
egp_file_path = "/path/to/your/project.egp"
output_csv_path = "/path/to/output_data_source_fields.csv"

extract_data_sources_and_fields_to_csv(
    egp_file_path, 
    output_csv_path
)
