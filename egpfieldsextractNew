import zipfile
import re
import csv
from collections import defaultdict

def extract_data_sources_and_fields_to_csv(egp_file, output_csv):
    # Extract the EGP file (essentially a ZIP file)
    with zipfile.ZipFile(egp_file, 'r') as z:
        # Look for .sas files and metadata within the project
        sas_files = [f for f in z.namelist() if f.endswith('.sas') or f.endswith('.xml')]

        # Data structures
        data_fields = defaultdict(set)  # Map of database.table -> variables

        # Regex patterns
        table_alias_regex = re.compile(
            r'\b([a-zA-Z0-9_]{9,}\.[a-zA-Z0-9_]+)\s+(?:as\s+)?([a-zA-Z0-9_]+)', 
            re.IGNORECASE
        )  # Matches `database.tablename alias` or `database.tablename AS alias`

        alias_field_regex = re.compile(
            r'\b([a-zA-Z0-9_]+)\.(\w+)\b', 
            re.IGNORECASE
        )  # Matches `alias.variable`

        alias_map = {}  # Map of alias -> database.table

        for file in sas_files:
            with z.open(file) as f:
                try:
                    content = f.read().decode('utf-8', errors='ignore')  # Read file content

                    # Find and store database.tablename and aliases
                    for table, alias in table_alias_regex.findall(content):
                        alias_map[alias] = table  # Map alias to the table

                    # Find and store fields associated with aliases
                    for alias, field in alias_field_regex.findall(content):
                        if alias in alias_map:  # If alias maps to a table
                            table = alias_map[alias]
                            data_fields[table].add(field)  # Map fields to the table
                except Exception as e:
                    print(f"Error reading {file}: {e}")

    # Write Data Source Fields to CSV
    with open(output_csv, 'w', newline='') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(["Database.Table", "Variable"])  # Header
        for table, fields in data_fields.items():
            for field in sorted(fields):  # Add table-variable mappings
                writer.writerow([table, field])

    print(f"Data source fields saved to {output_csv}")

# Usage example
egp_file_path = "/path/to/your/project.egp"
output_csv_path = "/path/to/output_data_source_fields.csv"

extract_data_sources_and_fields_to_csv(
    egp_file_path, 
    output_csv_path
)
