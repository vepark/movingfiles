import zipfile
import re
from collections import defaultdict
from openpyxl import Workbook

def extract_data_sources_and_fields_to_excel(egp_file, output_excel):
    # Extract the EGP file (essentially a ZIP file)
    with zipfile.ZipFile(egp_file, 'r') as z:
        # Look for .sas files and metadata within the project
        sas_files = [f for f in z.namelist() if f.endswith('.sas') or f.endswith('.xml')]

        data_sources = set()  # Use a set to deduplicate database.table names
        data_fields = defaultdict(set)  # Store fields for each database.table

        # Regex patterns
        table_regex = re.compile(
            r'\b(?:FROM|JOIN|INTO|TABLE)\s+([a-zA-Z0-9_]{9,}\.[a-zA-Z0-9_]+)\s*(?:AS\s+)?(\w+)?', 
            re.IGNORECASE
        )  # Matches database.table and optional alias

        field_regex = re.compile(
            r'\b(?:SELECT|GROUP BY|ON)\s+([\w\.,\s]+)', 
            re.IGNORECASE
        )  # Matches field lists in SELECT, GROUP BY, or ON clauses

        for file in sas_files:
            with z.open(file) as f:
                try:
                    content = f.read().decode('utf-8', errors='ignore')  # Read file content
                    
                    # Find database.table and their aliases
                    tables = table_regex.findall(content)
                    alias_map = {alias: table for table, alias in tables if alias}
                    data_sources.update([table for table, alias in tables])

                    # Extract fields associated with tables or aliases
                    sql_blocks = field_regex.findall(content)
                    for block in sql_blocks:
                        fields = [field.strip() for field in block.split(',') if '.' in field]
                        for field in fields:
                            if '.' in field:  # Match database.table.field or alias.field
                                table_alias, column = field.split('.', 1)
                                if table_alias in alias_map:  # Resolve alias to database.table
                                    data_fields[alias_map[table_alias]].add(column)
                                elif table_alias in data_sources:  # Direct database.table.field
                                    data_fields[table_alias].add(column)
                except Exception as e:
                    print(f"Error reading {file}: {e}")

    # Create an Excel workbook with two sheets
    workbook = Workbook()

    # Sheet 1: Data Sources
    sheet1 = workbook.active
    sheet1.title = "Data Sources"
    sheet1.append(["Database.Table"])  # Header
    for source in sorted(data_sources):  # Sort for consistency
        sheet1.append([source])

    # Sheet 2: Data Source Fields
    sheet2 = workbook.create_sheet(title="Data Source Fields")
    sheet2.append(["Database.Table", "Variable"])  # Header
    for table, fields in data_fields.items():
        for field in sorted(fields):  # Sort fields for consistency
            sheet2.append([table, field])

    # Save the Excel file
    workbook.save(output_excel)

    print(f"Data sources and fields extracted and saved to {output_excel}")

# Usage example
egp_file_path = "/path/to/your/project.egp"
output_excel_path = "/path/to/output_data_sources.xlsx"

extract_data_sources_and_fields_to_excel(
    egp_file_path, 
    output_excel_path
)
