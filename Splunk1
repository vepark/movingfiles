



import splunklib.client as client
import splunklib.results as results
import pandas as pd
import time
import logging

# Setup logging
logging.basicConfig(
    level=logging.DEBUG,  # Set logging level (DEBUG, INFO, WARNING, ERROR)
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler("splunk_query.log"),  # Log to a file
        logging.StreamHandler()  # Log to the console
    ]
)

# Splunk connection details
SPLUNK_HOST = "your_splunk_host"
SPLUNK_PORT = 8089
USERNAME = "your_username"
PASSWORD = "your_password"

# Splunk query
SPLUNK_QUERY = """
search index=wf_pvsi_other wf_id=EB5CL wf_env=PROD sourcetype="wf:ebscl:main.txt" RefMsgNm="*submitClaim*" OpName=logResponse earliest=-288d@d latest=-182d@d
| rex field=_raw max_match=1 "wf-customerid: (?<ECN>.*?)\\r"
| rex field=_raw max_match=1 "customerClaimNbr\":\"(?<claimNumber>[0-9]+)\""
| rex field=_raw max_match=1 "claimType\":\"(?<claimType>.*?)\""
| rex field=_raw max_match=1 "SORName\":\"(?<SORName>.*?)\""
| rex field=_raw max_match=1 "messageCode\":\"(?<crDecision>.*?)\""
| rex field=_raw max_match=0 "referenceNumber\":\"(?<refNbr>.*?)\""
| rex field=_raw max_match=0 "messageData\":\"(?<MsgData>.*?)\""
| search crDecision="Provisional Credit" AND SORName="LU"
| rename DT AS claimDateTime
| table ECN claimType SORName claimNumber crDecision refNbr crAmount claimDateTime MsgData
"""

# Connect to Splunk
try:
    logging.info("Connecting to Splunk...")
    service = client.connect(
        host=SPLUNK_HOST,
        port=SPLUNK_PORT,
        username=USERNAME,
        password=PASSWORD
    )
    logging.info("Connected to Splunk successfully.")
except Exception as e:
    logging.error(f"Failed to connect to Splunk: {e}")
    exit()

# Run the query with retry logic
MAX_RETRIES = 3
retry_count = 0
while retry_count < MAX_RETRIES:
    try:
        logging.info("Executing query...")
        job = service.jobs.create(SPLUNK_QUERY, exec_mode="blocking", adhoc_search_level="verbose")
        
        while not job.is_done():
            logging.debug("Waiting for the query to complete...")
            time.sleep(2)

        logging.info("Query executed successfully. Fetching results...")
        results_reader = results.JSONResultsReader(job.results(output_mode="json"))
        data = [result for result in results_reader if isinstance(result, dict)]
        
        # Save results to CSV
        df = pd.DataFrame(data)
        output_file = "splunk_results.csv"
        df.to_csv(output_file, index=False)
        logging.info(f"Results saved to {output_file}")
        break
    except Exception as e:
        logging.error(f"Error occurred: {e}")
        retry_count += 1
        if retry_count == MAX_RETRIES:
            logging.critical("Max retries reached. Exiting.")
            exit()





index=wf_pvsi_other wf_id=EB5CL wf_env=PROD sourcetype="wf:ebscl:main.txt"
| stats count, mean(crAmount) AS AvgCrAmount, stdev(crAmount) AS StdDevCrAmount, min(crAmount) AS MinCrAmount, max(crAmount) AS MaxCrAmount BY claimType
| eventstats avg(crAmount) AS OverallMean, stdev(crAmount) AS OverallStdDev
| eval isOutlier=if(crAmount < (OverallMean-2*OverallStdDev) OR crAmount > (OverallMean+2*OverallStdDev), "Yes", "No")
| stats count BY claimType, isOutlier
