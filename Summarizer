from selenium import webdriver

# Step 1: Open the browser and login
driver = webdriver.Chrome()
driver.get("https://prod.portal.wellsfargo.com/")

# Automate login
driver.find_element("id", "username").send_keys("your_username")
driver.find_element("id", "password").send_keys("your_password")
driver.find_element("id", "login-button").click()

# Step 2: Get cookies
cookies = driver.get_cookies()
for cookie in cookies:
    print(f"{cookie['name']}={cookie['value']}")

driver.quit()








import requests
from bs4 import BeautifulSoup
from transformers import pipeline

# Step 1: Define the target URL and headers with placeholders
url = "https://example.com/page"  # Replace with your target URL
headers = {
    "Cookie": "your_cookie_string_here",  # Replace with your cookie string
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
}

# Step 2: Fetch the webpage
response = requests.get(url, headers=headers)

if response.status_code == 200:
    print("Page retrieved successfully!")
else:
    print(f"Failed to retrieve the page. Status code: {response.status_code}")
    exit()

# Step 3: Parse the HTML content
soup = BeautifulSoup(response.text, "html.parser")
text = soup.get_text()  # Extract readable text
cleaned_text = " ".join(text.split())  # Clean up whitespace

# Step 4: Summarize the text using HuggingFace Transformers
summarizer = pipeline("summarization", model="facebook/bart-large-cnn")

# Set limits for summarization
max_length = 150  # Maximum length of the summary
min_length = 50   # Minimum length of the summary

try:
    summary = summarizer(cleaned_text, max_length=max_length, min_length=min_length, do_sample=False)
    print("\nSummary:\n", summary[0]["summary_text"])
except Exception as e:
    print(f"An error occurred during summarization: {e}")
